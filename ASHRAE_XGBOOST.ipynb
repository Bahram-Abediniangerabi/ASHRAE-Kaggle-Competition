{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ASHRAE-XGBOOST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfyiV26bC30y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gc\n",
        "import os\n",
        "import random\n",
        "\n",
        "import lightgbm as lgb\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost import plot_importance, plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pickle\n",
        "\n",
        "path_data = \"gdrive/My Drive/ASHRAE/\"\n",
        "path_train = path_data + \"train.csv\"\n",
        "path_test = path_data + \"test.csv\"\n",
        "path_building = path_data + \"building_metadata.csv\"\n",
        "path_weather_train = path_data + \"weather_train.csv\"\n",
        "path_weather_test = path_data + \"weather_test.csv\"\n",
        "\n",
        "\n",
        "seed = 2019\n",
        "random.seed(seed)\n",
        "plt.style.use('fivethirtyeight')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y-9shVGGi5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Start by connecting gdrive into the google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS50xzPTC8ui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Memory optimization\n",
        "\n",
        "# Original code from https://www.kaggle.com/gemartin/load-data-reduce-memory-usage by @gemartin\n",
        "# Modified to support timestamp type, categorical type\n",
        "# Modified to add option to use float16\n",
        "\n",
        "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
        "from pandas.api.types import is_categorical_dtype\n",
        "\n",
        "def reduce_mem_usage(df, use_float16=False):\n",
        "    \"\"\"\n",
        "    Iterate through all the columns of a dataframe and modify the data type to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    \n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
        "            continue\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == \"int\":\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype(\"category\")\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n",
        "    print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-07LAzcEDEOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data(X, building_data, weather_data, test=False):\n",
        "    \"\"\"\n",
        "    Preparing final dataset with all features.\n",
        "    \"\"\"\n",
        "    \n",
        "    X = X.merge(building_data, on=\"building_id\", how=\"left\")\n",
        "    X = X.merge(weather_data, on=[\"site_id\", \"timestamp\"], how=\"left\")\n",
        "    \n",
        "    #X.sort_values(\"timestamp\")\n",
        "    #X.reset_index(drop=True)\n",
        "    \n",
        "    gc.collect()\n",
        "    \n",
        "    holidays = [\"2016-01-01\", \"2016-01-18\", \"2016-02-15\", \"2016-05-30\", \"2016-07-04\",\n",
        "                \"2016-09-05\", \"2016-10-10\", \"2016-11-11\", \"2016-11-24\", \"2016-12-26\",\n",
        "                \"2017-01-02\", \"2017-01-16\", \"2017-02-20\", \"2017-05-29\", \"2017-07-04\",\n",
        "                \"2017-09-04\", \"2017-10-09\", \"2017-11-10\", \"2017-11-23\", \"2017-12-25\",\n",
        "                \"2018-01-01\", \"2018-01-15\", \"2018-02-19\", \"2018-05-28\", \"2018-07-04\",\n",
        "                \"2018-09-03\", \"2018-10-08\", \"2018-11-12\", \"2018-11-22\", \"2018-12-25\",\n",
        "                \"2019-01-01\"]\n",
        "    \n",
        "    X.timestamp = pd.to_datetime(X.timestamp, format=\"%Y-%m-%d %H:%M:%S\")\n",
        "    X.square_feet = np.log1p(X.square_feet)\n",
        "    \n",
        "    X[\"hour\"] = X.timestamp.dt.hour\n",
        "    X[\"month\"]=X.timestamp.dt.month\n",
        "    X[\"weekday\"] = X.timestamp.dt.weekday\n",
        "    X[\"is_holiday\"] = (X.timestamp.isin(holidays)).astype(int)\n",
        "    \n",
        "    drop_features = [\"timestamp\", \"sea_level_pressure\", \"wind_direction\", \"wind_speed\"]\n",
        "\n",
        "    X.drop(drop_features, axis=1, inplace=True)\n",
        "\n",
        "    if test:\n",
        "        row_ids = X.row_id\n",
        "        X.drop(\"row_id\", axis=1, inplace=True)\n",
        "        return X, row_ids\n",
        "    else:\n",
        "        y = np.log1p(X.meter_reading)\n",
        "        X.drop(\"meter_reading\", axis=1, inplace=True)\n",
        "        return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8i0rxGtjDIEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TRAIN MAKER\n",
        "\n",
        "def TRAINMAKER():\n",
        "    #get csv\n",
        "    df_train = pd.read_csv(path_train)\n",
        "    building = pd.read_csv(path_building)\n",
        "    #labelencode it\n",
        "    le = LabelEncoder()\n",
        "    building.primary_use = le.fit_transform(building.primary_use)\n",
        "    weather_train = pd.read_csv(path_weather_train)\n",
        "    #reduce memory\n",
        "    df_train = reduce_mem_usage(df_train, use_float16=True)\n",
        "    building = reduce_mem_usage(building, use_float16=True)\n",
        "    weather_train = reduce_mem_usage(weather_train, use_float16=True)\n",
        "    #make train set\n",
        "    X_train, y_train = prepare_data(df_train, building, weather_train)\n",
        "    \n",
        "    print('helo')\n",
        "    del df_train, weather_train,building\n",
        "    gc.collect()\n",
        "    \n",
        "    return X_train,y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYYLpTdEDL3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TEST MAKER\n",
        "def TESTMAKER():\n",
        "    df_test = pd.read_csv(path_test)\n",
        "    df_test = reduce_mem_usage(df_test)\n",
        "\n",
        "    weather_test = pd.read_csv(path_weather_test)\n",
        "    weather_test = reduce_mem_usage(weather_test)\n",
        "    \n",
        "    building = pd.read_csv(path_building)\n",
        "    building = reduce_mem_usage(building, use_float16=True)\n",
        "    \n",
        "    le = LabelEncoder()\n",
        "    building.primary_use = le.fit_transform(building.primary_use)\n",
        "    \n",
        "    X_test, row_ids = prepare_data(df_test, building, weather_test, test=True)\n",
        "    del df_test, building, weather_test\n",
        "    gc.collect()\n",
        "    return X_test,row_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ImEAE4bDO80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train,y_train=TRAINMAKER()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Dq8BZyKDQ8-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols=list(X_train.columns)\n",
        "models = []\n",
        "skf = GroupKFold(n_splits=6)\n",
        "a=0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Uw5-rT7DTQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, (idxT, idxV) in enumerate( skf.split(X_train, y_train, groups=X_train['month']) ):\n",
        "        month = X_train.iloc[idxV]['month'].iloc[0]\n",
        "        print('Fold',i,'withholding month',month)\n",
        "        print(' rows of train =',len(idxT),'rows of holdout =',len(idxV))\n",
        "        oof = []\n",
        "        reg =  xgb.XGBRegressor(\n",
        "                      n_estimators=2000,\n",
        "                      max_depth=12,\n",
        "                      num_boost_round=500,\n",
        "                      learning_rate=0.03,\n",
        "                      subsample=0.8,\n",
        "                      colsample_bytree=0.4,\n",
        "                      missing=np.nan,\n",
        "                      objective ='reg:squarederror',\n",
        "                      tree_method='gpu_hist'\n",
        "                      )\n",
        "        h = reg.fit(X_train[cols].iloc[idxT], y_train.iloc[idxT], \n",
        "                eval_set=[(X_train[cols].iloc[idxV],y_train.iloc[idxV])], verbose=100, early_stopping_rounds=500)\n",
        "    \n",
        "        oof = reg.predict(X_train[cols].iloc[idxV])\n",
        "        #preds += reg.predict_proba(X_test[cols])[:,1]/skf.n_splits\n",
        "        print('#'*20)\n",
        "        print ('OOF CV=',mean_squared_error(y_train.iloc[idxV],oof))\n",
        "        print('#'*20)\n",
        "       # models.append(reg)\n",
        "        pickle.dump(reg, open(\"thunder{}.pickle.dat\".format(a), \"wb\"))\n",
        "        a=a+1\n",
        "        del h, reg, oof\n",
        "        x=gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSUrS4HMDVY_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del X_train,y_train\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVd70uIXDXu2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test,row_ids=TESTMAKER()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcHWK0LLDcKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i=0\n",
        "a=0\n",
        "res=[]\n",
        "models=[]\n",
        "folds=6\n",
        "step_size = 50000\n",
        "for a in range(0,6):\n",
        "    models.append(pickle.load(open(\"thunder{}.pickle.dat\".format(a), \"rb\")))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJbqV7CMDd3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for a in models:\n",
        "    plot_importance(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk7b448wDgmt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for j in tqdm(range(int(np.ceil(X_test.shape[0]/50000)))):\n",
        "    res.append(np.expm1(sum([model.predict(X_test.iloc[i:i+step_size]) for model in models])/folds))\n",
        "    i+=step_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZvQIyT7Di53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res = np.concatenate(res)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zkm16r-_DlpG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission = pd.read_csv('gdrive/My Drive/ASHRAE/sample_submission.csv')\n",
        "submission['meter_reading'] = res\n",
        "submission.loc[submission['meter_reading']<0, 'meter_reading'] = 0\n",
        "submission.to_csv('submission-EXBOOST.csv', index=False)\n",
        "submission.sample(10)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}